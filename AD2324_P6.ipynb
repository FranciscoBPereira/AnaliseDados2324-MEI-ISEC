{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
 {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FranciscoBPereira/AnaliseDados2324-MEI-ISEC/blob/main/AD2324_P6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },

    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nAoTBKXUeLe"
      },
      "outputs": [],
      "source": [
        "# Setup, Version check and Common imports\n",
        "\n",
        "# Python ≥3.8 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### Task 1 ####\n",
        "\n",
        "# Using a pretrained neural network directly from Keras Applications to Classify Individual Images\n",
        "# https://keras.io/api/applications/\n",
        "\n",
        "# The ResNet-50 Model will be used to predict the category of selected images\n",
        "# https://keras.io/api/applications/resnet/#resnet50-function\n",
        "\n",
        "# Load Model with weights trained on Imagenet\n",
        "modelR = tf.keras.applications.ResNet50(weights=\"imagenet\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ZgrQ8ALT-PHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load two sample images and resize them to match the input required by ResNet\n",
        "\n",
        "from sklearn.datasets import load_sample_images\n",
        "\n",
        "images = load_sample_images()[\"images\"]\n",
        "images_resized = tf.keras.layers.Resizing(height=224, width=224, crop_to_aspect_ratio=True)(images)\n"
      ],
      "metadata": {
        "id": "y-2TsjUU-9ID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the images\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(images_resized[0]/255.0)\n",
        "plt.title('Palace')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('Dahlia')\n",
        "plt.imshow(images_resized[1]/255.0)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Syjr4W8f_40l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the sample images in a specific way that the model is expecting\n",
        "# Call method: resnet.preprocess_input()\n",
        "\n",
        "inputs = tf.keras.applications.resnet50.preprocess_input(images_resized)\n",
        "\n"
      ],
      "metadata": {
        "id": "khMFMaSZDq3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction with the pretrained model\n",
        "\n",
        "Y_proba = modelR.predict(inputs)\n",
        "\n",
        "print('Shape: ', Y_proba.shape)\n",
        "\n",
        "print('First Prediction: ', Y_proba[0])\n",
        "\n"
      ],
      "metadata": {
        "id": "9PwhnA3JEjRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Raw predictions are hard to understand\n",
        "# Check the top predicted classes\n",
        "\n",
        "top_K = tf.keras.applications.resnet50.decode_predictions(Y_proba, top=3)\n",
        "for image_index in range(len(images)):\n",
        "    print(f\"Image #{image_index}\")\n",
        "    for class_id, name, y_proba in top_K[image_index]:\n",
        "        print(f\"  {class_id} - {name:12s} {y_proba:.2%}\")\n"
      ],
      "metadata": {
        "id": "RKp-g_2oFKmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Are the results correct? How do you interpret the outcomes?"
      ],
      "metadata": {
        "id": "v7fk_sIXjWeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Task 2 ####\n",
        "\n",
        "# Transfer Learning using Pretrained Neural Networks\n",
        "# The same model ResNet-50 will be applied to the Flowers Dataset\n",
        "\n",
        "# Data Fetching and Loading\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "_URL = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "path_to_zip = tf.keras.utils.get_file('flower_photos', origin=_URL, untar=True, cache_dir=os.curdir)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'flower_photos')\n",
        "data_dir = pathlib.Path(PATH)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  shuffle=True,\n",
        "  batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  shuffle=True,\n",
        "  batch_size=batch_size)\n",
        "\n",
        "class_names = train_ds.class_names"
      ],
      "metadata": {
        "id": "5M08f0BPWXqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ResNet50 from Keras Applications\n",
        "\n",
        "ResNet_base = keras.applications.resnet50.ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
        "\n",
        "ResNet_base.trainable = False"
      ],
      "metadata": {
        "id": "SI44-R1vMA4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quiz 1**\n",
        "\n",
        "Explain the meaning of the following code snippets and justify why they are relevant for this transfer learning task:\n",
        "\n",
        "\n",
        "1.   include_top = False\n",
        "2.   ResNet_base.trainable = False\n"
      ],
      "metadata": {
        "id": "JOxkQCDAMOnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create the complete model\n",
        "# Adjust Image Size from (256, 256, 3) to (224, 224, 3)\n",
        "# Preprocess the images to meet what is expected by ResNet\n",
        "# Add GlobalAveragePooling + Classification Head\n",
        "\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "inputs = keras.Input(shape=(256, 256, 3))\n",
        "\n",
        "x = layers.Lambda(lambda image: tf.image.resize(image, (224,224)))(inputs)\n",
        "x = keras.applications.resnet.preprocess_input(x)\n",
        "x = ResNet_base(x, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "\n",
        "outputs = layers.Dense(5, activation='softmax')(x)\n",
        "\n",
        "\n",
        "model_TL1 = tf.keras.Model(inputs, outputs)\n"
      ],
      "metadata": {
        "id": "Nx_WPLX4MBCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quiz 2:**\n",
        "\n",
        "1.   Detail the changes that are performed to the images by the method preprocess_input()\n",
        "2.   How many weights has the feature extraction sub-model?\n",
        "\n"
      ],
      "metadata": {
        "id": "-YYmIhx6A0WA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_TL1.summary()"
      ],
      "metadata": {
        "id": "yTHOGsaNMBK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Compilation\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(epsilon=0.01)\n",
        "\n",
        "model_TL1.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        ")"
      ],
      "metadata": {
        "id": "M4dbXKASNzeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training (Preferably with a GPU)\n",
        "\n",
        "history = model_TL1.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=15,\n",
        ")"
      ],
      "metadata": {
        "id": "8Rfruc8KNzmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of Results\n",
        "\n",
        "import pandas as pd\n",
        "history_frame = pd.DataFrame(history.history)\n",
        "history_frame.loc[:, ['accuracy', 'val_accuracy']].plot()"
      ],
      "metadata": {
        "id": "5FXbyzWnNzse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Analyze results. By looking at the chart, what do you think is happening?\n"
      ],
      "metadata": {
        "id": "xrAqPAPS52rK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top layers are well-trained and now we can unfreeze the weights of the base\n",
        "\n",
        "ResNet_base.trainable = True\n",
        "\n",
        "# Compile again\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(epsilon=0.01)\n",
        "\n",
        "model_TL1.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        ")"
      ],
      "metadata": {
        "id": "aOj46uehZoUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_TL1.summary()"
      ],
      "metadata": {
        "id": "GtkI9SD0aFQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resume training.\n",
        "# It will take a while, even with a GPU. That's why we define a low number of training epochs\n",
        "\n",
        "history = model_TL1.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=5,\n",
        ")"
      ],
      "metadata": {
        "id": "DXjcj4IMaMzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of Results\n",
        "\n",
        "import pandas as pd\n",
        "history_frame = pd.DataFrame(history.history)\n",
        "history_frame.loc[:, ['accuracy', 'val_accuracy']].plot()"
      ],
      "metadata": {
        "id": "IvWp85A4ap5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Task 3 ####\n",
        "\n",
        "# Transfer Learning using anotgher Pretrained Neural Network\n",
        "# The model Xception will be applied to the Flowers Dataset https://keras.io/api/applications/xception/\n",
        "\n",
        "# Retrieve the original Xception model\n",
        "# Complete the neural network (don't forget preprocessing)\n",
        "# Train\n",
        "\n",
        "### Code goes here\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z441WtXvawsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quiz 3**\n",
        "\n",
        "Present the complete model that was created for the flowers dataset.\n",
        "This model must rely on the Xception network to perform feature extraction.\n"
      ],
      "metadata": {
        "id": "ofnZlrLPrRFC"
      }
    }
  ]
}
