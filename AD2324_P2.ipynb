{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JuSbzdc8UYX"
      },
      "outputs": [],
      "source": [
        "# Setup, Version check and Common imports\n",
        "\n",
        "# Python ≥3.8 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load CIFAR100 dataset from keras datasets:\n",
        "# https://keras.io/api/datasets/cifar100/\n",
        "# https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "# The load_data() method creates train and test sets. The parameter label_mode specifies the category labels: 'fine' or 'coarse'\n",
        "# In this class we will adopt the coarse classification, corresponding to 20 categories\n",
        "\n",
        "from keras.datasets import cifar100\n",
        "\n",
        "(train_images_full, train_labels_full), (test_images, test_labels) = cifar100.load_data(label_mode = 'coarse')\n",
        "\n",
        "train_labels_full = train_labels_full.squeeze()\n",
        "test_labels = test_labels.squeeze()\n",
        "\n",
        "# We further divide the original train datasets into train and validation datasets\n",
        "train_images = train_images_full[5000:]\n",
        "valid_images = train_images_full[:5000]\n",
        "\n",
        "train_labels = train_labels_full[5000:]\n",
        "valid_labels = train_labels_full[:5000]\n"
      ],
      "metadata": {
        "id": "QC1ftALm_dHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Complete this section\n",
        "# Confirm the dimensions of all tensors previously created\n",
        "\n",
        "# PLACE CODE HERE\n",
        "\n"
      ],
      "metadata": {
        "id": "5fU5y4rh_p8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quiz:\n",
        "\n",
        "What is the shape of the tensors? These dimensions correspond to what?\n",
        "\n",
        "How many elements does each of these sets have?\n",
        "\n",
        "Why do we need three sets?"
      ],
      "metadata": {
        "id": "K3lYrWjw_225"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize a few examples\n",
        "# Check here for the identification of the classes: https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "n_rows = 6\n",
        "n_cols = 10\n",
        "\n",
        "# Change the value of start to visualize different examples\n",
        "start = 0\n",
        "\n",
        "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        index = n_cols * row + col\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(train_images[index + start])\n",
        "        plt.axis('off')\n",
        "        plt.title(train_labels[index + start], fontsize=12)\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bo49AV1nAU-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n"
      ],
      "metadata": {
        "id": "EbIvQ4PjBcNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a feed-forward NN with Keras Sequential API: https://keras.io/api/models/\n",
        "\n",
        "# The base architecture is similar to the one used in the previous class\n",
        "# Complete the missing details:\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Flatten(input_shape=[32,32,3]),\n",
        "\n",
        "\n",
        "    # Complete model definition\n",
        "\n",
        "])\n"
      ],
      "metadata": {
        "id": "DTHggPBEBdfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Quiz:\n",
        "\n",
        "Explain all the details of the NN that was just created: Number of input nodes, number of output nodes, number of hidden layers and selection of activation functions.\n"
      ],
      "metadata": {
        "id": "29wA91ilB58N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Present a summary of the network architecture\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "T9yUOxPDBy7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Layer detailed analysis\n",
        "\n",
        "hidden1 = model.layers[1]\n",
        "weights, biases = hidden1.get_weights()\n",
        "\n",
        "print('Layer ', hidden1.name)\n",
        "print('Weights with shape ', weights.shape, ' :\\n', weights)\n",
        "print('Biases with shape ', biases.shape, ' :\\n', biases)\n"
      ],
      "metadata": {
        "id": "msfPQM2YCQnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ynDpMIO-CacN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quiz:\n",
        "\n",
        "How many weights has the NN?\n",
        "\n",
        "How many weights has the layer that was selected for detailed inspection?\n",
        "\n",
        "How were these weights initialized?\n",
        "\n"
      ],
      "metadata": {
        "id": "ni7NBG9aCadR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model compilation: https://keras.io/api/models/model_training_apis/\n",
        "# Three components have to be defined:\n",
        "# 1. the Optimizer to be used in training\n",
        "# 2. The loss function\n",
        "# 3. The evaluation metric\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "sROoIWQdCqZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "# Hyper-parameters: batch size and epochs\n",
        "# Validation datasets can also be provided\n",
        "\n",
        "# It returns a history object.\n",
        "# Its History.history attribute is a record of training loss values and metrics values at successive epochs,\n",
        "# as well as validation loss values and validation metrics values (if applicable).\n",
        "\n",
        "history = model.fit(train_images, train_labels, batch_size=32, epochs=20,\n",
        "                    validation_data=(valid_images, valid_labels))\n",
        "\n"
      ],
      "metadata": {
        "id": "TKzCp-bECuuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history.keys()\n"
      ],
      "metadata": {
        "id": "Ns8sVM6rC8NV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot the evolution of the accuracy metrics\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "x = pd.DataFrame(history.history, columns = ['accuracy', 'val_accuracy'])\n",
        "x.plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "hzME4ag3EQke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluation the generalization ability of the model\n",
        "# The test set will be used in this step\n",
        "# Classification of a set of examples can be performed using the evaluate() method:  https://keras.io/api/models/model_training_apis/\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test Accuracy: {test_acc}\")\n"
      ],
      "metadata": {
        "id": "fVr86_57ETsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quiz:\n",
        "\n",
        "How do you analyze these results?\n",
        "\n",
        "What is the difference between the validation and test datasets?\n",
        "\n",
        "Suggest some strategies to enhance accuracy.\n",
        "\n"
      ],
      "metadata": {
        "id": "rKrm8lBiEk_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model. All models details (architecture, configuration, weights) can be saved to disk.\n",
        "# The method save creates a folder with all the information\n",
        "\n",
        "model.save(\"Modelo_Aula2\")\n",
        "\n",
        "# The model can be later retrieved with the method load_model()\n"
      ],
      "metadata": {
        "id": "g8nTAvdXExks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model to png and save it to a file\n",
        "\n",
        "dot_img_file = 'model1.png'\n",
        "keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True, show_layer_activations=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "HUOm7kfIGrzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Challenge\n",
        "\n",
        "The performance of the neural network is poor. Design and test several changes, aiming at improving its performance.\n",
        "\n",
        "Some possibilites that can be tested are:\n",
        "\n",
        "i. Normalize the inputs: Try normalizing the inputs (together with a conversion to real values) and check if the performance changes\n",
        "\n",
        "ii. The proposed neural network may not be the most suitable for this problem. Change its architecture (number of layers / number of neurons per layer) and document how performance changes. The following constraints apply:\n",
        "\n",
        "a. The Keras Sequential API must be used\n",
        "\n",
        "b. Only Flatten and Dense layers can be used\n",
        "\n",
        "c. Activation functions: Sigmoid, Tanh, SoftMax\n",
        "\n",
        "d. Optimizer: SGD\n",
        "\n",
        "e. Budget: 3 million weights\n",
        "\n",
        "Perform some tests, document how results change and present a simple analysis of the outcome.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dlH7govfHQH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code goes here\n"
      ],
      "metadata": {
        "id": "vSPaajCZHHws"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}