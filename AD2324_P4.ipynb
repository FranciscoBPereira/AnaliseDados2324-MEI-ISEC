{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVoIRYXrYNGg"
      },
      "outputs": [],
      "source": [
        "# Setup, Version check and Common imports\n",
        "\n",
        "# Python ≥3.8 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Download a dataset containing pictures of cats and dogs\n",
        "# Method get_file() downloads and extracts information from the zip file:\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_file\n",
        "# The information is placed in the datasets folder of the current directory (confirm the division in sub-folders)\n",
        "\n",
        "import os\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True, cache_dir=os.curdir)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n"
      ],
      "metadata": {
        "id": "-qUxrTYbXjKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the images\n",
        "\n",
        "import pathlib\n",
        "\n",
        "data_dir = pathlib.Path(PATH)\n",
        "\n",
        "image_count = len(list(data_dir.glob('*/*/*.jpg')))\n",
        "print(image_count)"
      ],
      "metadata": {
        "id": "rabxXBjfk5pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create dataset for training and validation\n",
        "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
        "# https://www.tensorflow.org/guide/data\n",
        "\n",
        "# Method image_dataset_from_directory() creates a Dataset object from images located in a specified directory\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory\n",
        "# This method may shuffle images, adjust size and define the batch size\n",
        "# This way the dataset is (almost) ready to be processed by the neural network\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "\n",
        "IMG_SIZE = (160, 160)\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "train_ds = image_dataset_from_directory(train_dir, shuffle=True, seed=11, image_size=IMG_SIZE)\n",
        "val_ds = image_dataset_from_directory(validation_dir, shuffle=True, seed=11, image_size=IMG_SIZE)\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(1)\n",
        "val_ds = val_ds.cache().prefetch(1)\n"
      ],
      "metadata": {
        "id": "Dy9uFguPPlKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the dimension of the created datasets\n",
        "\n",
        "for image_batch, labels_batch in train_ds:\n",
        "    print(image_batch.shape)\n",
        "    print(labels_batch.shape)\n",
        "    break\n",
        "\n",
        "print('Class Names: ', class_names)"
      ],
      "metadata": {
        "id": "XU2Mo6WDmXGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Datasets are very important objects and they are associated with a large set of methods\n",
        "# https://www.tensorflow.org/guide/data\n",
        "\n",
        "for m in dir(tf.data.Dataset):\n",
        "    if not (m.startswith(\"_\") or m.endswith(\"_\")):\n",
        "        func = getattr(tf.data.Dataset, m)\n",
        "        if hasattr(func, \"__doc__\"):\n",
        "            print(\"● {:21s}{}\".format(m + \"()\", func.__doc__.split(\"\\n\")[0]))"
      ],
      "metadata": {
        "id": "L1eG_2S5r3Dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize a few examples\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy()/255.0) # the image from the dataset is transformed into a numpy array\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")\n"
      ],
      "metadata": {
        "id": "xwLmSbjupp--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n"
      ],
      "metadata": {
        "id": "WHZ6FyvC57jT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Model_FF - FEED-FORWARD NN\n",
        "\n",
        "# Create a feed-forward NN with Keras Sequential API: https://keras.io/api/models/\n",
        "\n",
        "# Complete with the following architecture\n",
        "# 4 hidden layers with 50 neurons each, He weight initialization and ReLU activation function\n",
        "# Last hidden layer must be suitable for a classification problem with 2 classes\n",
        "\n",
        "model_FF = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[160, 160, 3]),\n",
        "    keras.layers.Rescaling(1./255),\n",
        "\n",
        "    ### Complete the missing layers ###\n",
        "])"
      ],
      "metadata": {
        "id": "6nA7P4Lm596t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary\n",
        "\n",
        "model_FF.summary()"
      ],
      "metadata": {
        "id": "a2faH77Q9UyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model compilation\n",
        "# Define the loss function (https://keras.io/api/losses/)\n",
        "\n",
        "loss_FF = ### Add Definition here #\n",
        "\n",
        "model_FF.compile(loss=loss_FF,\n",
        "              optimizer=keras.optimizers.SGD(),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "iEbBZxXpCPRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train for 30 epochs\n",
        "\n",
        "history = model_FF.fit(train_ds, epochs=30, validation_data=val_ds)"
      ],
      "metadata": {
        "id": "nTbr2Q2ACkoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Results\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "x = pd.DataFrame(history.history, columns = ['accuracy', 'val_accuracy'])\n",
        "x.plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vF_3tSLPDgTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quiz 1: Present\n",
        "\n",
        "\n",
        "1.   The last layer selected for your network\n",
        "2.   The selected loss function\n",
        "3.   A brief analysis of results\n"
      ],
      "metadata": {
        "id": "nzoRoJCPvvRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In the second part of the worksheet, a CNN for this problem will be created\n",
        "\n",
        "# Before that, we will gain insight into the transformation performed by convolutional layers\n",
        "# Two exampl images from the dataset are selected for the study\n",
        "# In the code,  transformations are only applied to the first image\n",
        "# Perform changes in the code to apply the transformation also to the second image\n",
        "\n",
        "for images, labels in train_ds.take(1):\n",
        "    im1 = images[0].numpy()/255.0\n",
        "    label1 = labels[0]\n",
        "    im2 = images[1].numpy()/255.0\n",
        "    label2 = labels[1]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "ax = plt.subplot(1, 2, 1)\n",
        "plt.imshow(im1)\n",
        "plt.title(class_names[label1])\n",
        "plt.axis(\"off\")\n",
        "ax = plt.subplot(1, 2, 2)\n",
        "plt.imshow(im2)\n",
        "plt.title(class_names[label2])\n",
        "plt.axis(\"off\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BhnB-IXONcGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust Tensor dimensions (add batch dimension)\n",
        "\n",
        "im1 = tf.expand_dims(im1, axis=0)\n",
        "\n",
        "im1.shape"
      ],
      "metadata": {
        "id": "DOrdSFJIvFb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create vertical and random filters\n",
        "\n",
        "# The last dimension defines the number of output channels - in this example it is just one single feature map\n",
        "\n",
        "# You can try different filters and verify how the feature maps also change\n",
        "\n",
        "filter1 = np.zeros(shape=(7,7,3,1), dtype = np.float32)\n",
        "\n",
        "filter1[: , 3 , : ,] = 2\n",
        "filter1[: , 1 , : ,] = -1\n",
        "filter1[: , 5 , : ,] = -1\n",
        "\n",
        "filter2 = np.random.uniform(low=0.0, high=1.0, size=(7,7,3,1))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xegJSv_EvJmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize filter1\n",
        "\n",
        "a = filter1.squeeze()\n",
        "\n",
        "R = a[:,:,0]\n",
        "G = a[:,:,1]\n",
        "B = a[:,:,2]\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "ax = plt.subplot(1, 3, 1)\n",
        "plt.imshow(R)\n",
        "plt.title(\"R\")\n",
        "plt.axis(\"off\")\n",
        "ax = plt.subplot(1, 3, 2)\n",
        "plt.imshow(G)\n",
        "plt.title(\"G\")\n",
        "plt.axis(\"off\")\n",
        "ax = plt.subplot(1, 3, 3)\n",
        "plt.imshow(B)\n",
        "plt.title(\"B\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "quDZkyVYvNh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize filter2\n",
        "\n",
        "a = filter2.squeeze()\n",
        "\n",
        "R = a[:,:,0]\n",
        "G = a[:,:,1]\n",
        "B = a[:,:,2]\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "ax = plt.subplot(1, 3, 1)\n",
        "plt.imshow(R)\n",
        "plt.title(\"R\")\n",
        "plt.axis(\"off\")\n",
        "ax = plt.subplot(1, 3, 2)\n",
        "plt.imshow(G)\n",
        "plt.title(\"G\")\n",
        "plt.axis(\"off\")\n",
        "ax = plt.subplot(1, 3, 3)\n",
        "plt.imshow(B)\n",
        "plt.title(\"B\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "XSNloN-OVAj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply a convolutional layer with each one of the filters\n",
        "# The selected methods belong to the TensorFlow library\n",
        "# https://www.tensorflow.org/api_docs/python/tf/nn\n",
        "# https://www.tensorflow.org/api_docs/python/tf/nn/conv2d\n",
        "# Ainda não está a ser aplicada a função de ativação\n",
        "\n",
        "output1 = tf.nn.conv2d(im1, filter1, strides=1, padding=\"SAME\")\n",
        "output2 = tf.nn.conv2d(im1, filter2, strides=1, padding=\"SAME\")"
      ],
      "metadata": {
        "id": "6ElcnHFmvULf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the obtained feature maps (one for each filter)\n",
        "#https://www.tensorflow.org/api_docs/python/tf/squeeze\n",
        "\n",
        "fm1 = tf.squeeze(output1)\n",
        "fm2 = tf.squeeze(output2)\n",
        "\n",
        "plt.figure(figsize=(50, 50))\n",
        "\n",
        "ax = plt.subplot(1, 2, 1)\n",
        "plt.imshow(fm1, cmap=\"binary\")\n",
        "plt.title(\"Vertical\", fontsize=30)\n",
        "plt.axis(\"off\")\n",
        "ax = plt.subplot(1, 2, 2)\n",
        "plt.imshow(fm2, cmap=\"binary\")\n",
        "plt.title(\"Random\", fontsize=30)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "# Analyze image patterns"
      ],
      "metadata": {
        "id": "GLanbeJLvZFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply RELU activation function\n",
        "# https://www.tensorflow.org/api_docs/python/tf/nn/relu\n",
        "\n",
        "final1 = tf.nn.relu(output1)\n",
        "final2 = tf.nn.relu(output2)"
      ],
      "metadata": {
        "id": "_AhMAyv6vdaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the obtained feature maps (one for each filter)\n",
        "# https://www.tensorflow.org/api_docs/python/tf/squeeze\n",
        "\n",
        "fmF1 = tf.squeeze(final1)\n",
        "fmF2 = tf.squeeze(final2)\n",
        "\n",
        "plt.figure(figsize=(50, 50))\n",
        "\n",
        "ax = plt.subplot(1, 2, 1)\n",
        "plt.imshow(fmF1, cmap=\"binary\")\n",
        "plt.title(\"Vertical\", fontsize=30)\n",
        "plt.axis(\"off\")\n",
        "ax = plt.subplot(1, 2, 2)\n",
        "plt.imshow(fmF2, cmap=\"binary\")\n",
        "plt.title(\"Random\", fontsize=30)\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "vf2h1MMBvgNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply MaxPool layer\n",
        "\n",
        "pool1 = tf.nn.max_pool(final1, 2, strides=2, padding=\"SAME\")\n",
        "pool2 = tf.nn.max_pool(final2, 2, strides=2, padding=\"SAME\")"
      ],
      "metadata": {
        "id": "QjWhUotLvoCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the obtained feature maps (one for each filter)\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "\n",
        "p1 = tf.squeeze(pool1)\n",
        "p2 = tf.squeeze(pool2)\n",
        "\n",
        "ax = plt.subplot(1, 2, 1)\n",
        "plt.imshow(p1, cmap=\"binary\")\n",
        "plt.title(\"Vertical\", fontsize=30)\n",
        "plt.axis(\"off\")\n",
        "ax = plt.subplot(1, 2, 2)\n",
        "plt.imshow(p2, cmap=\"binary\")\n",
        "plt.title(\"Random\", fontsize=30)\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "KQtEaMxFvq0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model_CNN - Convolutional Neural Network\n",
        "\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "73FwnaDDvswM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a simple CNN\n",
        "\n",
        "# Add the final classification layer to the model\n",
        "\n",
        "model_CNN = keras.models.Sequential([\n",
        "    layers.Rescaling(1./255, input_shape=(160,160,3)),\n",
        "    layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(32, 3, activation='relu',padding='same'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, activation='relu',padding='same'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "     ### Complete the last layer ###\n",
        "])\n"
      ],
      "metadata": {
        "id": "Fcn3akHcv3RN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_CNN.summary()"
      ],
      "metadata": {
        "id": "sO7NvcgMwo0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model compilation\n",
        "# Define the loss function\n",
        "\n",
        "lossCNN = ### Define the loss function ###\n",
        "\n",
        "model_CNN.compile(loss= lossCNN,\n",
        "              optimizer=keras.optimizers.SGD(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history = model_CNN.fit(train_ds, epochs=30, validation_data=val_ds)"
      ],
      "metadata": {
        "id": "sG8NGAD5wx2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the evolution of the accuracy metrics\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "x = pd.DataFrame(history.history, columns = ['accuracy', 'val_accuracy'])\n",
        "x.plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_p98AgUdxOtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quiz 2:\n",
        "\n",
        "1.   How many weights has each kernel/filter of the second convolutional layer?\n",
        "2.   How many feature maps are generated by the last convolutional layer?\n",
        "3.   What is the dimension of each one of these feature maps?"
      ],
      "metadata": {
        "id": "D5AZcAuU-xJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quiz 3:\n",
        "\n",
        "How do you analyse the results obtained by this CNN?"
      ],
      "metadata": {
        "id": "QSdBfFwUP8F0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Design and implement one change in the CNN and repeat the training process,\n",
        "# seeking for an architecture that performs more effectively.\n",
        "\n",
        "# Among other possibilities, you might consider one of the following points:\n",
        "#  1. Change the CNN architecture, adding, deleting, or changing the parameterization of convolutional, maxpooling or dense layers.\n",
        "#  2. Add Batch Normalization and/or Dropout layers.\n",
        "#  3. Add a callback to implement Early Stopping.\n",
        "\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "# Create a new model called model_CNN2\n",
        "\n",
        "\n",
        "###  CODE GOES HERE   ####\n",
        "\n"
      ],
      "metadata": {
        "id": "U60GDXegxdwU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}